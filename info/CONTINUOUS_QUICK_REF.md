# ğŸ¤– AUTONOMOUS DISCOVERY - QUICK REFERENCE

## One-Line Starters

```bash
# Run everything automatically (RECOMMENDED)
python continuous_runner.py

# Aggressive discovery (find lots of sources)
python continuous_runner.py --discovery 10 --scrape 60

# Gentle discovery (respect servers, run longer)
python continuous_runner.py --discovery 60 --scrape 1440

# See detailed logs
python continuous_runner.py --verbose

# Just test discovery once
python source_discovery.py
```

---

## How It Works (Visual)

```
                    START
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ DISCOVERY (30 min)   â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚ âœ“ Search web         â”‚
          â”‚ âœ“ Analyze events     â”‚
          â”‚ âœ“ Check links        â”‚
          â”‚ âœ“ Learn patterns     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ SCRAPING (6 hours)   â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚ âœ“ Get ALL sources    â”‚
          â”‚ âœ“ Extract events     â”‚
          â”‚ âœ“ Store in DB        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ AI VALIDATION        â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚ âœ“ Check quality      â”‚
          â”‚ âœ“ Remove spam        â”‚
          â”‚ âœ“ Categorize         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ REPEAT FOREVER       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What Gets Discovered

```
PHASE 1: Search Web
â”œâ”€ "London tech events"
â”œâ”€ "London developer meetups"
â”œâ”€ "London hackathons 2026"
â”œâ”€ "best tech events London"
â””â”€ (15+ search queries)
   â†“
   Finds: Eventbrite, Meetup, specialized sites
   

PHASE 2: Analyze Events
â”œâ”€ Look at 100 existing events
â”œâ”€ Extract URLs from descriptions
â”œâ”€ Visit those URLs
â””â”€ Add if they're event-related
   â†“
   Finds: Linked event sites
   

PHASE 3: Check Links
â”œâ”€ Visit known event sites
â”œâ”€ Extract all outgoing links
â”œâ”€ Check if they link to other events
â””â”€ Validate & add
   â†“
   Finds: Partner sites, secondary sources
```

---

## Files Created

| File | Purpose |
|------|---------|
| `continuous_runner.py` | Main orchestrator - runs everything |
| `source_discovery.py` | Intelligent discovery & learning |
| `discovered_sources.json` | Learned sources (grows over time) |
| `CONTINUOUS_DISCOVERY_GUIDE.md` | Full documentation |

---

## Real-Time Monitoring

### Watch Discovered Sources Grow

```bash
# Check how many sources found
python -c "import json; s=json.load(open('discovered_sources.json')); print(f'{len(s)} sources found!')"

# List all sources
python -c "import json; print(json.dumps(json.load(open('discovered_sources.json')), indent=2))"
```

### Watch Database Grow

```bash
# Count events
python -c "import sqlite3; c=sqlite3.connect('database.db'); print(f'{c.cursor().execute(\"SELECT COUNT(*) FROM events\").fetchone()[0]} events!')"

# Count validated
python -c "import sqlite3; c=sqlite3.connect('database.db'); print(f'{c.cursor().execute(\"SELECT COUNT(*) FROM events WHERE is_valid=1\").fetchone()[0]} validated!')"
```

### Live Dashboard (One-Liner)

```bash
# Watch stats update every 5 seconds (Linux/Mac)
watch -n 5 "python -c \"import json, sqlite3; s=json.load(open('discovered_sources.json')); c=sqlite3.connect('database.db'); cur=c.cursor(); cur.execute('SELECT COUNT(*) FROM events'); tot=cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM events WHERE is_valid=1'); val=cur.fetchone()[0]; print(f'Sources: {len(s)} | Total Events: {tot} | Validated: {val}')\""
```

---

## Comparison Table

| Mode | Discovery | Scrape | Best For | Start With |
|------|-----------|--------|----------|-----------|
| **Default** | 30 min | 6 hrs | Balanced | âœ… YES |
| **Aggressive** | 10 min | 1 hr | Growing DBs | After testing |
| **Gentle** | 60 min | 24 hrs | Live servers | Production |
| **Manual** | Once | Once | Testing | --discovery.py |

---

## System Output Example

```
ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€
AUTONOMOUS CONTINUOUS EVENT DISCOVERY & SCRAPING SYSTEM
ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€

âš™ï¸ CONFIGURATION
  Discovery interval: 30 minutes
  Scrape interval:    360 minutes
  Verbose mode:       OFF

âœ¨ System is fully autonomous and continuously:
   â€¢ Discovers new event sources
   â€¢ Scrapes all available sources
   â€¢ Validates events with AI
   â€¢ Updates the database
   â€¢ Learns and adapts

ğŸ’¡ Press Ctrl+C to stop

ğŸ”„ INITIAL STARTUP SEQUENCE

ğŸ“ Scraping eventbrite...
  âœ“ Found 6 events
ğŸ“ Scraping ltw...
  âœ“ Found 5 events

============================================================
âœ… SCRAPING COMPLETE
============================================================
Total events found:   11
Events inserted:      11
Errors encountered:   0

ğŸ¤– SOURCE DISCOVERY CYCLE - Machine Learning Mode
============================================================

ğŸ“¡ PHASE 1: Search-Based Discovery
  ğŸ” Searching: 'London tech events websites'
    (searching... please wait)
    âœ¨ Discovered: https://example-event-site.com
  ğŸ” Searching: 'London developer meetups'
    âœ¨ Discovered: https://another-events.co.uk

ğŸ“¡ PHASE 2: Event-Based Discovery
  ğŸ”— Analyzing existing events for new sources...
  (no new sources found)

ğŸ“¡ PHASE 3: Link Analysis Discovery
  ğŸŒ Analyzing links on known event sites...
    âœ¨ Linked from eventbrite: https://partnered-events.com

âœ… PHASE 4: Validation & Integration
  âœ“ Added: https://example-event-site.com (discovery)
  âœ“ Added: https://another-events.co.uk (hackathon)
  âœ“ Added: https://partnered-events.com (learning)

============================================================
ğŸ“Š DISCOVERY SUMMARY
============================================================
Candidates found:     47
Validated & added:    9
Total sources:        32
Tried (invalid):      38

ğŸ“Š CONTINUOUS RUNNER STATUS
================================================================================

ğŸ” SOURCE DISCOVERY
  Total sources discovered:  32
  Last discovery run:        2026-01-28 14:32:15
  Next discovery in:         29m 43s

ğŸ“¥ EVENTS
  Total in database:         145
  Validated & active:        87
  Pending validation:        58
  Last scrape run:           2026-01-28 14:28:00
  Next scrape in:            5h 32m

ğŸ“ˆ LIFETIME STATS
  Total sources discovered:  32
  Total events scraped:      145

================================================================================

â³ Next cycle in 30 minutes...
   (Press Ctrl+C to stop)
```

---

## Command Examples

```bash
# Start with default settings (BEST FOR BEGINNERS)
python continuous_runner.py

# Fast discovery (test phase)
python continuous_runner.py --discovery 5

# Slow/gentle (production)
python continuous_runner.py --discovery 120 --scrape 1440

# Verbose debugging
python continuous_runner.py --verbose

# See help
python continuous_runner.py --help

# Stop any time
# Just press: Ctrl+C
```

---

## Key Statistics After Different Time Periods

```
â±ï¸ After 1 hour:
â”œâ”€ 8-12 sources discovered
â”œâ”€ 50-80 events
â””â”€ System stable âœ“

â±ï¸ After 6 hours:
â”œâ”€ 20-30 sources discovered
â”œâ”€ 200-300 events
â””â”€ AI validating âœ“

â±ï¸ After 24 hours:
â”œâ”€ 50-100 sources discovered
â”œâ”€ 500-1000 events
â”œâ”€ Patterns learned âœ“
â””â”€ Self-improving âœ“

â±ï¸ After 1 week:
â”œâ”€ 100-200 sources discovered
â”œâ”€ 2000-5000 events
â”œâ”€ Strong patterns âœ“
â””â”€ Near-complete coverage âœ“
```

---

## Troubleshooting Quick Fixes

| Problem | Solution |
|---------|----------|
| **Too slow** | `--discovery 10 --scrape 60` |
| **Too aggressive** | `--discovery 60 --scrape 1440` |
| **Not finding sources** | Check internet, wait 1 hour |
| **Database errors** | Delete `database.db`, restart |
| **API errors** | Check `.env` has valid OpenAI key |
| **Want to pause** | Just press Ctrl+C |

---

## Next Steps

```
1. START:           python continuous_runner.py
2. WAIT:            Let it run for 1 hour
3. CHECK:           Look at discovered_sources.json
4. MONITOR:         Watch web server at http://127.0.0.1:5000
5. DEPLOY:          When happy, run 24/7 on server
```

---

**Your system is now a self-learning event discovery machine! ğŸ¤–**
